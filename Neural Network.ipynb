{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "  def __init__(self, weights, bias):\n",
    "    self.weights = weights\n",
    "    self.bias = bias\n",
    "\n",
    "  def feedforward(self, inputs):\n",
    "    # Weight inputs, add bias, then use the activation function\n",
    "    total = np.dot(self.weights, inputs) + self.bias\n",
    "    return sigmoid(total)\n",
    "\n",
    "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
    "bias = 4                   # b = 4\n",
    "n = Neuron(weights, bias)\n",
    "\n",
    "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
    "print(n.feedforward(x))    # 0.9990889488055994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ... code from previous section here\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "  Each neuron has the same weights and bias:\n",
    "    - w = [0, 1]\n",
    "    - b = 0\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    weights = np.array([0, 1])\n",
    "    bias = 0\n",
    "\n",
    "    # The Neuron class here is from the previous section\n",
    "    self.h1 = Neuron(weights, bias)\n",
    "    self.h2 = Neuron(weights, bias)\n",
    "    self.o1 = Neuron(weights, bias)\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    out_h1 = self.h1.feedforward(x)\n",
    "    out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "    # The inputs for o1 are the outputs from h1 and h2\n",
    "    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "\n",
    "    return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x)) # 0.7216325609518421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "y_true = np.array([1, 0, 0, 1])\n",
    "y_pred = np.array([0, 0, 0, 0])\n",
    "\n",
    "print(mse_loss(y_true, y_pred)) # 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "\n",
    "  *** DISCLAIMER ***:\n",
    "  The code below is intended to be simple and educational, NOT optimal.\n",
    "  Real neural net code looks nothing like this. DO NOT use this code.\n",
    "  Instead, read/run it to understand how this specific network works.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "\n",
    "    # Biases\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    return o1\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "    - all_y_trues is a numpy array with n elements.\n",
    "      Elements in all_y_trues correspond to those in data.\n",
    "    '''\n",
    "    learn_rate = 0.1\n",
    "    epochs = 1000 # number of times to loop through the entire dataset\n",
    "\n",
    "    result_array = np.array([])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "\n",
    "        # --- Calculate partial derivatives.\n",
    "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "\n",
    "        # Neuron o1\n",
    "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Neuron h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "        # Neuron h2\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Neuron h1\n",
    "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "        # Neuron h2\n",
    "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "        # Neuron o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "      # --- Calculate total loss at the end of each epoch\n",
    "      if epoch % 10 == 0:\n",
    "        y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "        loss = mse_loss(all_y_trues, y_preds)\n",
    "        #print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "        result_array = np.append(result_array, loss)\n",
    "        \n",
    "    return result_array\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# Define dataset\n",
    "data = np.array([\n",
    "  [-2, -1],  # Alice\n",
    "  [25, 6],   # Bob\n",
    "  [17, 4],   # Charlie\n",
    "  [-15, -6], # Diana\n",
    "])\n",
    "all_y_trues = np.array([\n",
    "  1, # Alice\n",
    "  0, # Bob\n",
    "  0, # Charlie\n",
    "  1, # Diana\n",
    "])\n",
    "\n",
    "# Train our neural network!\n",
    "network = OurNeuralNetwork()\n",
    "result_array = network.train(data, all_y_trues)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily: 0.948\n",
      "Frank: 0.040\n"
     ]
    }
   ],
   "source": [
    "# Make some predictions\n",
    "emily = np.array([-7, -3]) # 128 pounds, 63 inches\n",
    "frank = np.array([20, 2])  # 155 pounds, 68 inches\n",
    "print(\"Emily: %.3f\" % network.feedforward(emily)) # 0.951 - F\n",
    "print(\"Frank: %.3f\" % network.feedforward(frank)) # 0.039 - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
